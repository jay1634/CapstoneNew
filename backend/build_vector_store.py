from pathlib import Path
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

# =========================
# ‚úÖ CORRECTED PATHS
# =========================
PROJECT_ROOT = Path(__file__).resolve().parents[1]

CORPUS_DIR = PROJECT_ROOT / "data" / "corpus"
VECTOR_DIR = PROJECT_ROOT / "backend" / "vector_store"

VECTOR_DIR.mkdir(parents=True, exist_ok=True)

print("üìÇ CORPUS DIRECTORY:", CORPUS_DIR)
print("üìÇ VECTOR STORE DIRECTORY:", VECTOR_DIR)

# =========================
# ‚úÖ EMBEDDINGS
# =========================
embeddings = OllamaEmbeddings(model="mistral")

# =========================
# ‚úÖ TEXT SPLITTER
# =========================
splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=150,
)

# =========================
# ‚úÖ LOAD DOCUMENTS
# =========================
def load_documents():
    if not CORPUS_DIR.exists():
        raise RuntimeError(f"‚ùå Corpus directory not found: {CORPUS_DIR}")

    files = list(CORPUS_DIR.glob("*.txt"))
    if not files:
        raise RuntimeError(f"‚ùå No .txt files found in: {CORPUS_DIR}")

    documents = []

    for file in files:
        text = file.read_text(encoding="utf-8", errors="ignore").strip()
        chunks = splitter.split_text(text)

        for i, chunk in enumerate(chunks):
            documents.append(
                Document(
                    page_content=chunk,
                    metadata={
                        "source": file.name,
                        "chunk": i,
                    },
                )
            )

    print(f"‚úÖ Loaded {len(documents)} chunks from {len(files)} files")
    return documents


# =========================
# ‚úÖ BUILD FAISS INDEX
# =========================
def build_faiss():
    docs = load_documents()

    print("‚ö° Creating embeddings...")
    db = FAISS.from_documents(docs, embeddings)

    db.save_local(VECTOR_DIR)

    print("‚úÖ FAISS INDEX BUILT SUCCESSFULLY")
    print("üìÅ Files created:")
    print("   - index.faiss")
    print("   - index.pkl")


# =========================
# ‚úÖ RUN
# =========================
if __name__ == "__main__":
    print("üîÑ Building FAISS index from corpus...")
    build_faiss()
